{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import importlib\n",
    "from tqdm.auto import tqdm #from functools import cache\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "import pickle\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import LogFormatter, MaxNLocator\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "direc = os.getcwd()\n",
    "os.chdir(\"/home/b/b381737/python_scripts/master/open_data\")\n",
    "import open_data_utils #import the module here, so that it can be reloaded.\n",
    "importlib.reload(open_data_utils)\n",
    "from open_data_utils import xr_to_gdf, add_country_names, country_intersections, select_extent, FlexDataset, FlexDataCollection, load_nc_partposit, FlexDataset2, calc_enhancement\n",
    "os.chdir(direc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(name='dask-cluster',\n",
    "                        cores=8,\n",
    "                        processes=8,\n",
    "                        n_workers=8,\n",
    "                        memory='10GB',\n",
    "                        interface='ib0',\n",
    "                        queue='prepost',\n",
    "                        project='bb1170',\n",
    "                        walltime='12:00:00',\n",
    "                        asynchronous=0)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"/mnt/lustre02/work/bb1170/static/CT2019/Conc3hour_3x2/\"\n",
    "file_dummy = \"CT2019B.molefrac_glb3x2_\"\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/Darwin/wu200k/grid_time_20091207210000.nc\"\n",
    "fd = FlexDataset2(file, extent=[0, 180,-80,30], ct_dir=dir_name, ct_name_dummy=file_dummy, chunks=dict(time=20, pointspec=4))\n",
    "fp = fd.footprint\n",
    "fig, ax = fp.plot()\n",
    "_ = fd.add_map(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.enhancement(ct_file, allow_read=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/test_traj0/grid_time_20091127230000.nc\"\n",
    "fd = FlexDataset2(file, extent=[0, 180,-80,30], ct_dir=dir_name, ct_name_dummy=file_dummy, chunks=dict(time=20, pointspec=4))\n",
    "tr = fd.trajectories\n",
    "tr.ct_endpoints()\n",
    "tr.co2_from_endpoints()\n",
    "tr.load_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.background(allow_read=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207\"\n",
    "setups = [\"wu_setup\", \"pressure_setup\", \"pressure_wu_setup\", \"pressure_wu_fewer_setup\", \"test_setup\", \"wu_setup_2\", \"wu_fewer_setup\", \"wu_more_setup\", \"wu_setup_CT-grid\", \"wu_setup_CT-grid_mixing_ratio\"]\n",
    "\n",
    "wu_file = os.path.join(dir_path, setups[0], \"grid_time_20091207210000.nc\")\n",
    "pr_file = os.path.join(dir_path, setups[1], \"grid_time_20091207210000.nc\")\n",
    "pw_file = os.path.join(dir_path, setups[2], \"grid_time_20091207210000.nc\")\n",
    "pwf_file = os.path.join(dir_path, setups[3], \"grid_time_20091207210000.nc\")\n",
    "test_file = os.path.join(dir_path, setups[4], \"grid_time_20091207210000.nc\")\n",
    "wu_33_file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI_33-60_20091123-20091207/wu/grid_time_20091207210000.nc\"\n",
    "wu2_file = os.path.join(dir_path, setups[5], \"grid_time_20091207210000.nc\")\n",
    "wu_few_file = os.path.join(dir_path, setups[6], \"grid_time_20091207210000.nc\")\n",
    "wu_more_file = os.path.join(dir_path, setups[7], \"grid_time_20091207210000.nc\")\n",
    "wu_ct_file = os.path.join(dir_path, setups[8], \"grid_time_20091207210000.nc\")\n",
    "wu_ct_mr_file = os.path.join(dir_path, setups[9], \"grid_time_20091207210000.nc\")\n",
    "wu_100_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/Wollongong/wu100k/grid_time_20091207210000.nc\")\n",
    "pr_100_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/Wollongong/pressure100k/grid_time_20091207210000.nc\")\n",
    "unit_w_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_rel_height/unit_wollongong/grid_time_20091207210000.nc\")\n",
    "unit_d_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_rel_height/unit_darwin/grid_time_20091207210000.nc\")\n",
    "unit_d_long_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/sensitivity_rel_time/wu40k_darwin/grid_time_20091207210000.nc\")\n",
    "unit_w_long_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/sensitivity_rel_time/wu40k_wollongong/grid_time_20091207210000.nc\")\n",
    "unit_d_long_shift_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/sensitivity_rel_time/wu40k_darwin_shift/grid_time_20091207210000.nc\")\n",
    "unit_w_long_shift_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/sensitivity_rel_time/wu40k_wollongong_shift/grid_time_20091207210000.nc\")\n",
    "unit_d_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/trajectories/unit_darwin040k/grid_time_20091207210000.nc\")\n",
    "unit_w_file = os.path.join(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091116-20091207/trajectories/unit_wollongong040k/grid_time_20091207210000.nc\")\n",
    "ea_file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/test/grid_time_20091127230000.nc\"\n",
    "ea_single_file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EA_test_box/grid_time_20091127230000.nc\"\n",
    "\n",
    "#fd = FlexDataset(dir_path + file_path, extent=[100,180,-60,0], chunks=dict(time=15, pointspec=4))\n",
    "extent = [30,180,-80,0]\n",
    "chunks = dict(time=15, pointspec=4)\n",
    "#chunks=None\n",
    "#fd_wu = FlexDataset(wu_file, extent, chunks=chunks, name=\"Wu Setup\", cmaps=\"Reds\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pr = FlexDataset(pr_file, extent, chunks=chunks, name=\"Pressure Setup\", cmaps=\"Blues\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pw = FlexDataset(pw_file, extent, chunks=chunks, name=\"Pressure Wu Setup\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pwf = FlexDataset(pwf_file, extent, chunks=chunks, name=\"Pressure Wu (fewer) Setup\", cmaps=\"Purples\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_test = FlexDataset(test_file, extent, chunks=chunks, name=\"Test Setup\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_33 = FlexDataset(wu_33_file, extent, chunks=chunks, name=\"Wu Setup 33-60\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu2 = FlexDataset(wu2_file, extent, chunks=chunks, name=\"Wu Setup 2\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_few = FlexDataset(wu_few_file, extent, chunks=chunks, name=\"Wu (less particles)\", cmaps=\"Reds\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_more = FlexDataset(wu_more_file, extent, chunks=chunks, name=\"Wu (more particles)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_ct = FlexDataset(wu_ct_file, extent, chunks=chunks, name=\"Wu (Carbon Tracker grid)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_ct_mr = FlexDataset(wu_ct_mr_file, extent, chunks=chunks, name=\"Wu (Carbon Tracker grid, mr)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu_100 = FlexDataset(wu_100_file, extent, chunks=chunks, name=\"Wu (100k parts)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "#fd_pr_100 = FlexDataset(pr_100_file, extent, chunks=chunks, name=\"Pressure (100k parts)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "#fd_unit_w = FlexDataset(unit_w_file, extent, chunks=chunks, name=\"Unit (100k parts)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "#fd_unit_d = FlexDataset(unit_d_file, extent, chunks=chunks, name=\"Unit (100k parts)\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\"])\n",
    "#fd_unit_d_long = FlexDataset(unit_d_long_file, chunks=chunks, name=\"Unit (40k parts)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Darwin\"])\n",
    "#fd_unit_w_long = FlexDataset(unit_w_long_file, chunks=chunks, name=\"Unit (40k parts)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "#fd_unit_d_long_shift = FlexDataset(unit_d_long_shift_file, chunks=chunks, name=\"Unit (40k parts, shifted)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Darwin\"])\n",
    "#fd_unit_w_long_shift = FlexDataset(unit_w_long_shift_file, chunks=chunks, name=\"Unit (40k parts, shifted)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "#fd_unit_d = FlexDataset(unit_d_file, chunks=chunks, name=\"Unit Darwin (40k parts)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Darwin\"])\n",
    "#fd_unit_w = FlexDataset(unit_w_file, chunks=chunks, name=\"Unit Wollongong (40k parts)\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "fd_ea = FlexDataset(ea_file, chunks=chunks, name=\"ERA 5 data\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])\n",
    "fd_single_ea = FlexDataset(ea_single_file, chunks=dict(time=10, pointspec=400), name=\"ERA 5 data\", cmaps=\"jet\", norm=colors.LogNorm(), station_names=[\"Wollongong\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extent = [30,180,-80,0]\n",
    "chunks = dict(time=15, pointspec=4)\n",
    "dir_path = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207\"\n",
    "set_path = [\"05grid\",\"10grid\",\"20grid\"]\n",
    "setups = [\"wu_setup\", \"pressure_setup\", \"pressure_wu_setup\"]\n",
    "\n",
    "fd_wu05_file = os.path.join(dir_path, set_path[0], setups[0], \"grid_time_20091207210000.nc\")\n",
    "fd_pr05_file = os.path.join(dir_path, set_path[0], setups[1], \"grid_time_20091207210000.nc\")\n",
    "fd_pw05_file = os.path.join(dir_path, set_path[0], setups[2], \"grid_time_20091207210000.nc\")\n",
    "fd_wu10_file = os.path.join(dir_path, set_path[1], setups[0], \"grid_time_20091207210000.nc\")\n",
    "fd_pr10_file = os.path.join(dir_path, set_path[1], setups[1], \"grid_time_20091207210000.nc\")\n",
    "fd_pw10_file = os.path.join(dir_path, set_path[1], setups[2], \"grid_time_20091207210000.nc\")\n",
    "fd_wu20_file = os.path.join(dir_path, set_path[2], setups[0], \"grid_time_20091207210000.nc\")\n",
    "fd_pr20_file = os.path.join(dir_path, set_path[2], setups[1], \"grid_time_20091207210000.nc\")\n",
    "fd_pw20_file = os.path.join(dir_path, set_path[2], setups[2], \"grid_time_20091207210000.nc\")\n",
    "\n",
    "\n",
    "#fd_wu05 = FlexDataset(fd_wu05_file, extent, chunks=chunks, name=\"Wu 0.5°\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pr05 = FlexDataset(fd_pr05_file, extent, chunks=chunks, name=\"Pressure 0.5°\", cmaps=\"Blues\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pw05 = FlexDataset(fd_pw05_file, extent, chunks=chunks, name=\"Pressure Wu 0.5°\", cmaps=\"Reds\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu10 = FlexDataset(fd_wu10_file, extent, chunks=chunks, name=\"Wu 1°\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pr10 = FlexDataset(fd_pr10_file, extent, chunks=chunks, name=\"Pressure 1°\", cmaps=\"Blues\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pw10 = FlexDataset(fd_pw10_file, extent, chunks=chunks, name=\"Pressure Wu 1°\", cmaps=\"Reds\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_wu20 = FlexDataset(fd_wu20_file, extent, chunks=chunks, name=\"Wu 2°\", cmaps=\"Greens\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pr20 = FlexDataset(fd_pr20_file, extent, chunks=chunks, name=\"Pressure 2°\", cmaps=\"Blues\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])\n",
    "#fd_pw20 = FlexDataset(fd_pw20_file, extent, chunks=chunks, name=\"Pressure Wu 2°\", cmaps=\"Reds\", norm=colors.LogNorm(), station_names=[\"Darwin\", \"Wollongong\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one footprint \n",
    "fd = fd_ea\n",
    "fd.extent = [60,180,-60,0]\n",
    "for i in [0]:\n",
    "    station = i\n",
    "    fig, ax = fd.subplots(figsize=(12,4))\n",
    "    fd.plot_footprint(ax, station=station, plot_station=True, cmap=\"jet\",station_kwargs=dict(color=\"black\", label=fd.station_names[station]), cbar_kwargs=dict(label=\"s*m^3/kg\"))\n",
    "    fd.add_map(ax)\n",
    "    ax.set_title(f\"Footprint with {fd.name}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot one footprint \n",
    "dtype=\"datetime64[D]\"\n",
    "for day in range(5,10):\n",
    "    fd = fd_unit_w\n",
    "    fd.extent = [-180,180,-80,40]\n",
    "    for i in [0]:\n",
    "        station = i\n",
    "        fig, ax = fd.subplots(figsize=(12,4))\n",
    "        fd.plot(ax, station=station, time=np.arange(-(day+1)*8,-day*8), pointspec=np.arange(len(fd.DataSet.pointspec)), plot_station=True, cmap=\"jet\",station_kwargs=dict(color=\"black\", label=fd.station_names[station]), cbar_kwargs=dict(label=\"s*m^3/kg\"))\n",
    "        fd.add_map(ax)\n",
    "        ax.set_title(f\"Footprint {fd.DataSet.time[-(day+1)*8].values.astype(dtype)} - {fd.DataSet.time[-day*8].values.astype(dtype)}\")\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot differences\n",
    "fd1 = fd_unit_w_long\n",
    "fd2 = fd_unit_w_long_shift\n",
    "diff = fd2.Footprints[0]-fd1.Footprints[0]\n",
    "fig, ax = fd1.subplots(figsize=(10,4.5))\n",
    "diff.plot(ax=ax,cmap=\"seismic\", cbar_kwargs=dict(label=\"Footprint[s]\"))\n",
    "fd1.add_map(ax=ax, )\n",
    "ax.set_title(f\"{fd2.name} and {fd1.name}\")\n",
    "#plt.savefig(\"figures/australia/column_setups/diff_wu_pr.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fds = [fd_wu, fd_wu_33]\n",
    "\n",
    "vmin = 1\n",
    "vmax = 0\n",
    "for i,fd in enumerate(fds):\n",
    "    vmin = fd.vmin() if fd.vmin()<vmin else vmin\n",
    "    vmax = fd.vmax() if fd.vmax()>vmax else vmax\n",
    "\n",
    "station = 1\n",
    "setup = [\"Wu\", \"Pressure Wu\"]\n",
    "\n",
    "for i,fd in enumerate(fds):\n",
    "    fig, ax = plt.subplots(figsize=(10,10), subplot_kw=dict(projection=ccrs.PlateCarree())) if i == 0 else (fig,ax)\n",
    "    fd.plot_footprint(ax, station, plot_station=True, vmin=vmin, vmax=vmax, cbar_kwargs=dict(label=f\"Footprint [s] ({fd.name})\", orientation=\"horizontal\", pad=0.035))\n",
    "    fd.add_map(ax) if i == 0 else None\n",
    "    ax.set_title(\"Comparison of Footprints\")\n",
    "plt.savefig(\"figures/australia/column_setups/33_vs_normal.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fds.reverse()\n",
    "for i,fd in enumerate(fds):\n",
    "    fig, ax = plt.subplots(figsize=(10,10), subplot_kw=dict(projection=ccrs.PlateCarree())) if i == 0 else (fig,ax)\n",
    "    fd.plot_footprint(ax, station, plot_station=True, vmin=vmin, vmax=vmax, cbar_kwargs=dict(label=f\"Footprint [s] ({fd.name})\", orientation=\"horizontal\", pad=0.035))\n",
    "    fd.add_map(ax) if i == 0 else None\n",
    "    ax.set_title(\"Comparison of Footprints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fds = [fd_wu05, fd_pr05, fd_pw05]\n",
    "station = 0\n",
    "rel = []\n",
    "for ind in range(len(fds)):\n",
    "    inds = np.delete(np.arange(len(fds)), ind)\n",
    "\n",
    "    columns =[\"Setup\",\"Footprint sum\", f\"Total difference to {fds[ind].name}\", f\"Relative difference to {fds[ind].name}\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    comp_fd = fds[ind]\n",
    "    comp_vals = comp_fd.Footprints[station].values\n",
    "    for j, i in enumerate(inds):\n",
    "        fd = fds[i]\n",
    "        vals = fd.Footprints[station].values\n",
    "        line = [fd.name, vals.sum(), np.sum(np.abs(comp_vals-vals)), np.sum(np.abs(comp_vals-vals))/comp_vals.sum()]\n",
    "        df.loc[len(df)] = line\n",
    "        rel.append(np.sum(np.abs(comp_vals-vals))/comp_vals.sum())\n",
    "    display(df)\n",
    "    \n",
    "fds = [fd_wu10, fd_pr10, fd_pw10]\n",
    "station = 0\n",
    "for ind in range(len(fds)):\n",
    "    inds = np.delete(np.arange(len(fds)), ind)\n",
    "\n",
    "    columns =[\"Setup\",\"Footprint sum\", f\"Total difference to {fds[ind].name}\", f\"Relative difference to {fds[ind].name}\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    comp_fd = fds[ind]\n",
    "    comp_vals = comp_fd.Footprints[station].values\n",
    "    for j, i in enumerate(inds):\n",
    "        fd = fds[i]\n",
    "        vals = fd.Footprints[station].values\n",
    "        line = [fd.name, vals.sum(), np.sum(np.abs(comp_vals-vals)), np.sum(np.abs(comp_vals-vals))/comp_vals.sum()]\n",
    "        df.loc[len(df)] = line\n",
    "        rel.append(np.sum(np.abs(comp_vals-vals))/comp_vals.sum())\n",
    "    display(df)\n",
    "\n",
    "fds = [fd_wu20, fd_pr20, fd_pw20]\n",
    "station = 0\n",
    "for ind in range(len(fds)):\n",
    "    inds = np.delete(np.arange(len(fds)), ind)\n",
    "\n",
    "    columns =[\"Setup\",\"Footprint sum\", f\"Total difference to {fds[ind].name}\", f\"Relative difference to {fds[ind].name}\"]\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    comp_fd = fds[ind]\n",
    "    comp_vals = comp_fd.Footprints[station].values\n",
    "    for j, i in enumerate(inds):\n",
    "        fd = fds[i]\n",
    "        vals = fd.Footprints[station].values\n",
    "        line = [fd.name, vals.sum(), np.sum(np.abs(comp_vals-vals)), np.sum(np.abs(comp_vals-vals))/comp_vals.sum()]\n",
    "        df.loc[len(df)] = line\n",
    "        rel.append(np.sum(np.abs(comp_vals-vals))/comp_vals.sum())\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = np.array(rel).reshape(3,6)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot([0.5,1,2], rel.mean(axis=1))\n",
    "plt.xlabel(\"grid size [°]\")\n",
    "plt.ylabel(\"average relative error\")\n",
    "plt.title(\"(setup2 - setup1)/setup2\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setups = [\"Wu Setup\", \"Pressure Setup\", \"Pressure Wu Setup\"]\n",
    "ppm1 = [.312, .283, .318]\n",
    "ppm2 = [.74, .85, .748]\n",
    "ppm = [ppm1, ppm2]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Setup\", \"station\", \"Enhancement (ppm)\", \"Relative difference to Wu Setup\"])\n",
    "for i, ppms in enumerate(ppm):\n",
    "    for j, p in enumerate(ppms):\n",
    "        line = [setups[j], i, p, (ppms[0]-p)/ppms[0]]\n",
    "        df.loc[len(df)] = line\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times,rel_diffs)\n",
    "plt.title(f\"({fd2.name} - {fd1.name})/sum of {fd2.name}\")\n",
    "plt.xlabel(\"timestep\")\n",
    "plt.ylabel(\"relative difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions from multiple files\n",
    "end = '2009-12-07' \n",
    "start = '2009-11-23'\n",
    "\n",
    "site = \"Darwin\"\n",
    "\n",
    "gosat_file = '/work/bb1170/static/REMOTECv240_L2_CO2_GOSAT/REMOTEC_L2_CO2_GOSAT_'\n",
    "tccon_file = \"/work/bb1170/static/TCCON/data/gosat/netcdf/wg*.public.nc\"\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\"\n",
    "\n",
    "enh_dict = dict()\n",
    "for name in [\"wu\",\"pressure\"]:\n",
    "    enh_dict[name] = dict(values=[], number=[])\n",
    "    #for num in [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"20\",\"30\",\"40\",\"50\",\"60\",\"70\",\"80\",\"90\",\"100\"]:\n",
    "    #for num in [\"001\",\"002\", \"003\",\"004\",\"005\",\"006\",\"007\",\"008\",\"009\",\"010\",\"011\",\"012\",\"013\",\"014\",\"015\",\"016\",\"017\",\"018\",\"019\", \"020\",\"030\",\"040\",\"050\",\"060\",\"070\",\"080\",\"090\",\"100\"]:\n",
    "    #for num in [\"001\",\"002\", \"003\",\"004\",\"005\",\"006\",\"007\",\"008\",\"009\",\"010\",\"011\",\"012\",\"013\",\"015\",\"016\",\"017\",\"018\",\"019\", \"020\",\"030\",\"040\",\"050\",\"060\",\"080\",\"090\",\"100\"]:\n",
    "    for num in [\"200\",\"300\",\"400\", \"500\", \"600\", \"700\", \"800\", \"900\", \"1000\"]:\n",
    "        fp_file = f\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/{site}/\"+name+num+\"k/grid_time_20091207210000.nc\"\n",
    "        if not os.path.exists(fp_file):\n",
    "            print(\"skipped\")\n",
    "            continue\n",
    "        #try:\n",
    "        ds = xr.open_dataset(fp_file, chunks=dict(time=20, pointspec=4))\n",
    "        enh= calc_enhancement(ds, ct_file,1013, start, end)\n",
    "        enh_dict[name][\"values\"].append(enh)\n",
    "        enh_dict[name][\"number\"].append(int(num))\n",
    "        #except:\n",
    "        #    print(\"exception\")\n",
    "        #if not os.path.exists(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/Darwin/\"+name+num+\"k/grid_time_20091207210000.nc\"):\n",
    "        print(name+num)\n",
    "        #print(os.path.exists(f\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_part_nums/{site}/\"+name+num+\"k/grid_time_20091207210000.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"data/enhancements_darwin.json\", \"w\") as f:\n",
    "#    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot emission results with error bands\n",
    "station = \"wollongong\"\n",
    "\n",
    "xlim = (-5, 1005)\n",
    "percentages = [0.2, 0.1]\n",
    "\n",
    "with open(f'data/enhancements_{station}.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "for name in [\"wu\",\"pressure\"]:\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.grid()\n",
    "    plt.xlabel(r\"Released particles [$10^3$ particles]\")\n",
    "    plt.ylabel(\"Enhancement\")\n",
    "    plt.xlim(*xlim)\n",
    "    plt.title(f\"Effect of particle number ({station})\")\n",
    "    vals = np.array(data[name][\"values\"])\n",
    "    nums = np.array(data[name][\"number\"])\n",
    "    val_diff = vals[-1] - vals\n",
    "    plt.errorbar(nums, vals, fmt=\"o\", label=name, color=\"black\")\n",
    "    plt.hlines(vals[-1],*xlim ,color=\"grey\",alpha=0.7, linestyle=\"dashed\")\n",
    "    plt.fill_between([*xlim], (1+percentages[0])*vals[-1], (1+percentages[1])*vals[-1] ,color=\"orange\",alpha=0.3, linestyle=\"dashed\", label=f\"{percentages[1]*1e2}% deviation\")\n",
    "    plt.fill_between([*xlim], (1-percentages[1])*vals[-1], (1-percentages[0])*vals[-1] ,color=\"orange\",alpha=0.3, linestyle=\"dashed\")\n",
    "    plt.fill_between([*xlim], (1+percentages[1])*vals[-1], (1-percentages[1])*vals[-1] ,color=\"red\",alpha=0.3, linestyle=\"dashed\", label=f\"{percentages[0]*1e2}% deviation\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/part_num_{station}_{name}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot multiple results\n",
    "station = \"wollongong\"\n",
    "with open(f'data/enhancements_{station}.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "    \n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid()\n",
    "plt.xlabel(r\"Released particles [$10^3$ particles]\")\n",
    "plt.ylabel(\"Enhancement\")\n",
    "plt.title(f\"Effect of particle number ({station})\")\n",
    "for name in [\"wu\",\"pressure\"]:\n",
    "    vals = np.array(data[name][\"values\"])\n",
    "    nums = np.array(data[name][\"number\"])\n",
    "    val_diff = vals[-1] - vals\n",
    "    plt.errorbar(nums, vals, fmt=\"o\", label=name, )\n",
    "    plt.legend()\n",
    "#plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/part_num_{station}_all.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot difference to last value\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid()\n",
    "plt.xlabel(r\"Released particles [$10^3$ particles]\")\n",
    "plt.ylabel(r\"Relative difference to $10^6$ measurement\")\n",
    "plt.title(f\"Effect of particle number\")\n",
    "\n",
    "marker = [\"o\", \"x\"]\n",
    "colors = [\"b\",\"r\"]#[\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "for i, station in enumerate([\"darwin\", \"wollongong\"]):\n",
    "    with open(f\"data/enhancements_{station}.json\", 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    for j, name in enumerate([\"wu\",\"pressure\"]):\n",
    "        vals = np.array(data[name][\"values\"])\n",
    "        nums = np.array(data[name][\"number\"])\n",
    "        val_diff = vals[-1] - vals\n",
    "        rel_diff = val_diff/vals[-1]\n",
    "        abs_diff = abs(rel_diff)\n",
    "        plt.errorbar(nums, rel_diff, fmt=marker[j], color=colors[i], label=f\"{name} ({station})\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/part_num_total_1m.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of release height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# effect on sum of footprints\n",
    "fd = fd_unit_w\n",
    "\n",
    "fp_sum = []\n",
    "fp = fd.Footprints[0]\n",
    "arr = fd.DataArrays[0]\n",
    "arr = arr.sum(dim=[\"time\", \"longitude\", \"latitude\"]).compute()\n",
    "for i in range(len(fd.DataSet.pointspec.values)):\n",
    "    if i==0: continue\n",
    "    x = arr.isel(pointspec=slice(0,i))\n",
    "    x = x.sum(dim=\"pointspec\").compute()\n",
    "    fp_sum.append(x)\n",
    "fp_arr = np.array(fp_sum)[:,0,0]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(fd.DataSet.RELZZ2.values[1:], fp_arr)\n",
    "plt.title(f\"Effect of maximum height in {fd.station_names[0]} (footprint sum)\")\n",
    "plt.xlabel(\"Maximum Release height [m]\")\n",
    "plt.ylabel(\"Footprint sum [s m^3/kg]\")\n",
    "plt.grid()\n",
    "plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/rel_height_{fd.station_names[0]}_fp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of enhancements with different HEIGHTS included\n",
    "fd = fd_unit_d\n",
    "\n",
    "end = '2009-12-07' \n",
    "start = '2009-11-23'\n",
    "\n",
    "gosat_file = '/work/bb1170/static/REMOTECv240_L2_CO2_GOSAT/REMOTEC_L2_CO2_GOSAT_'\n",
    "tccon_file = \"/work/bb1170/static/TCCON/data/gosat/netcdf/wg*.public.nc\"\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\"\n",
    "#fp_file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_rel_height/unit/grid_time_20091207210000.nc\"\n",
    "fp_data = fd.DataSet\n",
    "\n",
    "enh_list = []\n",
    "height_list = []\n",
    "for i in range(len(fd.DataSet.pointspec.values)):\n",
    "    if i==0: continue\n",
    "    if (i%3) != 0: continue\n",
    "    fp = fp_data.isel(pointspec=slice(0,i), numpoint=slice(0,i))\n",
    "    enh, _ = calc_emission(fp, tccon_file, ct_file, gosat_file, start, end)\n",
    "    enh_list.append(enh)\n",
    "    height_list.append(fp.RELZZ2.values[-1])\n",
    "enh_dict = {}\n",
    "enh_dict[\"values\"] = list(np.array(enh_list).astype(float))\n",
    "enh_dict[\"heights\"] = list(np.array(height_list).astype(float))\n",
    "with open(f\"{fd.directory}/enhancements_heights.json\", \"w\") as f:\n",
    "    json.dump(enh_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = fd_unit_w\n",
    "with open(f'{fd.directory}/enhancements_heights.json', 'r') as fp:\n",
    "    enh_dict = json.load(fp)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(f\"Effect of maximum height in {fd.station_names[0]} (enhancement)\")\n",
    "plt.ylabel(\"Enhancement\")\n",
    "plt.xlabel(\"Maximal height [m]\")\n",
    "plt.plot(enh_dict[\"heights\"], enh_dict[\"values\"])\n",
    "plt.grid()\n",
    "plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/rel_height_{fd.station_names[0]}_enh.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculation of enhancements with different TIMES included\n",
    "fd = fd_unit_d_long_shift\n",
    "\n",
    "end = '2009-12-07' \n",
    "start = '2009-11-16'\n",
    "\n",
    "gosat_file = '/work/bb1170/static/REMOTECv240_L2_CO2_GOSAT/REMOTEC_L2_CO2_GOSAT_'\n",
    "tccon_file = \"/work/bb1170/static/TCCON/data/gosat/netcdf/wg*.public.nc\"\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\"\n",
    "#fp_file = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20091123-20091207/sensitivity_rel_height/unit/grid_time_20091207210000.nc\"\n",
    "fp_data = fd.DataSet\n",
    "\n",
    "enh_list = []\n",
    "time_list = []\n",
    "for i in range(len(fd.DataSet.time.values)):\n",
    "    if i==0: continue\n",
    "    if (i%8) != 0: continue\n",
    "    fp = fp_data.isel(time=slice(0, i))\n",
    "    enh, _ = calc_emission(fp, tccon_file, ct_file, gosat_file, start, end)\n",
    "    enh_list.append(enh)\n",
    "    time_list.append(fp.time.values[-1])\n",
    "enh_dict = {}\n",
    "enh_dict[\"values\"] = list(np.array(enh_list).astype(float))\n",
    "enh_dict[\"times\"] = list(np.array(time_list))\n",
    "with open(f\"{fd.directory}/enhancements_times.json\", \"w\") as f:\n",
    "    json.dump(enh_dict, f, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enh_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fd in [fd_unit_w_long_shift, fd_unit_w_long]:\n",
    "    fd = fd\n",
    "    with open(f'{fd.directory}/enhancements_times.json', 'r') as fp:\n",
    "        enh_dict = json.load(fp)\n",
    "        enh_dict[\"times\"] = np.array(enh_dict[\"times\"]).astype(\"datetime64\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(f\"Effect of run duration in {fd.station_names[0]} (enhancement)\")\n",
    "    plt.ylabel(\"Enhancement\")\n",
    "    plt.xlabel(\"Run time\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.plot(enh_dict[\"times\"], enh_dict[\"values\"])\n",
    "    plt.grid()\n",
    "    #plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/run_time_{fd.station_names[0]}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(7,4))\n",
    "plt.title(f\"Enhamcement comparison 1 hour shift (Darwin)\")\n",
    "plt.ylabel(\"Enhancement\")\n",
    "plt.xlabel(\"Run time\")\n",
    "plt.gca().invert_xaxis()\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "for fd in [fd_unit_d_long_shift, fd_unit_d_long]:\n",
    "    fd = fd\n",
    "    with open(f'{fd.directory}/enhancements_times.json', 'r') as fp:\n",
    "        enh_dict = json.load(fp)\n",
    "        enh_dict[\"times\"] = np.array(enh_dict[\"times\"]).astype(\"datetime64\")\n",
    "        plt.plot(enh_dict[\"times\"], enh_dict[\"values\"], label=fd.name)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(6))\n",
    "plt.legend()\n",
    "plt.savefig(f\"/mnt/lustre01/pf/b/b381737/python_scripts/figures/sensitivity/rel_time_40k_{fd.station_names[0]}.png\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.set_major_locator(MaxNLocator(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carbon Tracker plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = '2009-12-07' \n",
    "start = '2009-12-01'\n",
    "\n",
    "enddate = datetime.date(int(end[0:4]),int(end[5:7]),int(end[8:10]))\n",
    "startdate = datetime.date(int(start[0:4]),int(start[5:7]),int(start[8:10]))\n",
    "\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\"\n",
    "first = True\n",
    "for date in pd.date_range(startdate, enddate):\n",
    "    fileCT = ct_file+str(date.year)+str(date.month).zfill(2)+str(date.day).zfill(2)+'.nc'\n",
    "    DSCTfluxday = xr.open_mfdataset(fileCT, combine='by_coords',drop_variables = 'time_components', chunks=\"auto\")\n",
    "    if first:\n",
    "        first = False\n",
    "        DSCTflux = DSCTfluxday\n",
    "    else:\n",
    "        DSCTflux = xr.concat([DSCTflux,DSCTfluxday],dim = 'time')\n",
    "\n",
    "#calculate Satelite CO2 enhancement\n",
    "\n",
    "#sum flux components: \n",
    "DSCT_totalflux = DSCTflux.bio_flux_opt+DSCTflux.ocn_flux_opt+DSCTflux.fossil_flux_imp+DSCTflux.fire_flux_imp\n",
    "DSCT_totalflux.name = 'total_flux'\n",
    "\n",
    "#can be deleted when footprint has -179.5 coordinate\n",
    "DSCT_totalflux = DSCT_totalflux[:,:,1:]\n",
    "DSCT_totalflux = DSCT_totalflux.where(DSCT_totalflux!=0)\n",
    "print(DSCT_totalflux.time.values[[0,-1]])\n",
    "flux = DSCT_totalflux.sum(dim=\"time\").compute()\n",
    "fd.extent = [-180,180,-80,40]\n",
    "fig, ax = fd.subplots(figsize=(12,4))\n",
    "\n",
    "fd_unit_w.add_map(ax)\n",
    "#ax.set_title(f\"Footprint with {fd.name}\")\n",
    "#plt.legend(loc=\"upper right\")\n",
    "flux.plot(ax=ax, vmin=-0.00005,vmax=0.00005, cmap=\"bwr\")#, cbar_kwargs=dict(orientation=\"horizontal\"))\n",
    "plt.title(\"Coarbon tracker fluxes\")\n",
    "plt.show()\n",
    "# Plot one footprint \n",
    "fd = fd_unit_w\n",
    "fd.extent = [-180,180,-80,40]\n",
    "\n",
    "inds = [0, 8*6+5]\n",
    "for i in [0]:\n",
    "    station = i\n",
    "    fig, ax = fd.subplots(figsize=(12,4))\n",
    "    fd.plot(ax,time=np.arange(*inds), pointspec=np.arange(len(fd.DataSet.pointspec)), station=station, plot_station=True, cmap=\"jet\",station_kwargs=dict(color=\"black\", label=fd.station_names[station]), cbar_kwargs=dict(label=\"s*m^3/kg\"))\n",
    "    fd.add_map(ax)\n",
    "    ax.set_title(f\"Footprint with {fd.name}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = '2009-12-01' \n",
    "start = '2009-11-24'\n",
    "\n",
    "enddate = datetime.date(int(end[0:4]),int(end[5:7]),int(end[8:10]))\n",
    "startdate = datetime.date(int(start[0:4]),int(start[5:7]),int(start[8:10]))\n",
    "\n",
    "ct_file = \"/work/bb1170/static/CT2019/Flux3hour_1x1/CT2019B.flux1x1.\"\n",
    "first = True\n",
    "for date in pd.date_range(startdate, enddate):\n",
    "    fileCT = ct_file+str(date.year)+str(date.month).zfill(2)+str(date.day).zfill(2)+'.nc'\n",
    "    DSCTfluxday = xr.open_mfdataset(fileCT, combine='by_coords',drop_variables = 'time_components', chunks=\"auto\")\n",
    "    if first:\n",
    "        first = False\n",
    "        DSCTflux = DSCTfluxday\n",
    "    else:\n",
    "        DSCTflux = xr.concat([DSCTflux,DSCTfluxday],dim = 'time')\n",
    "\n",
    "#calculate Satelite CO2 enhancement\n",
    "\n",
    "#sum flux components: \n",
    "DSCT_totalflux = DSCTflux.bio_flux_opt+DSCTflux.ocn_flux_opt+DSCTflux.fossil_flux_imp+DSCTflux.fire_flux_imp\n",
    "DSCT_totalflux.name = 'total_flux'\n",
    "\n",
    "#can be deleted when footprint has -179.5 coordinate\n",
    "DSCT_totalflux = DSCT_totalflux[:,:,1:]\n",
    "DSCT_totalflux = DSCT_totalflux.where(DSCT_totalflux!=0)\n",
    "print(DSCT_totalflux.time.values[[0,-1]])\n",
    "flux = DSCT_totalflux.sum(dim=\"time\").compute()\n",
    "fd.extent = [-180,180,-80,40]\n",
    "fig, ax = fd.subplots(figsize=(12,4))\n",
    "\n",
    "fd_unit_w.add_map(ax)\n",
    "#ax.set_title(f\"Footprint with {fd.name}\")\n",
    "#plt.legend(loc=\"upper right\")\n",
    "flux.plot(ax=ax, vmin=-0.00005,vmax=0.00005, cmap=\"bwr\")#, cbar_kwargs=dict(orientation=\"horizontal\"))\n",
    "plt.title(\"Coarbon tracker fluxes\")\n",
    "\n",
    "# Plot one footprint \n",
    "fd = fd_unit_w\n",
    "fd.extent = [-180,180,-80,40]\n",
    "\n",
    "inds = [8*6-1, 9*13-8]\n",
    "for i in [0]:\n",
    "    station = i\n",
    "    fig, ax = fd.subplots(figsize=(12,4))\n",
    "    fd.plot(ax,time=np.arange(*inds), pointspec=np.arange(len(fd.DataSet.pointspec)), station=station, plot_station=True, cmap=\"jet\",station_kwargs=dict(color=\"black\", label=fd.station_names[station]), cbar_kwargs=dict(label=\"s*m^3/kg\"))\n",
    "    print(fd.DataSet.time.values[inds][::-1])\n",
    "    fd.add_map(ax)\n",
    "    ax.set_title(f\"Footprint with {fd.name}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one footprint \n",
    "fd = fd_unit_w\n",
    "fd.extent = [-180,180,-80,40]\n",
    "\n",
    "inds = [8*6+1, 9*13-10]\n",
    "for i in [0]:\n",
    "    station = i\n",
    "    fig, ax = fd.subplots(figsize=(12,4))\n",
    "    fd.plot(ax,time=np.arange(*inds), pointspec=np.arange(len(fd.DataSet.pointspec)), station=station, plot_station=True, cmap=\"jet\",station_kwargs=dict(color=\"black\", label=fd.station_names[station]), cbar_kwargs=dict(label=\"s*m^3/kg\"))\n",
    "    print(fd.DataSet.time.values[inds])\n",
    "    fd.add_map(ax)\n",
    "    ax.set_title(f\"Footprint with {fd.name}\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animation():\n",
    "    def __init__(self, fd):\n",
    "        self.fig = plt.figure(figsize=(20,5))\n",
    "        self.ax0 = self.fig.add_subplot(121, projection=ccrs.PlateCarree())\n",
    "        self.ax1 = self.fig.add_subplot(122)\n",
    "        print(self.fig.axes)\n",
    "        self.fd = fd\n",
    "        self.fd.extent = [-120,180,-80,40]\n",
    "        with open(f'{fd.directory}/enhancements_times.json', 'r') as fp:\n",
    "            enh_dict = json.load(fp)\n",
    "            enh_dict[\"times\"] = np.array(enh_dict[\"times\"]).astype(\"datetime64\")\n",
    "        self.enh_dict = enh_dict\n",
    "        #self.line, = self.fig.axes[1].plot(enh_dict[\"times\"], enh_dict[\"values\"], color=\"black\")\n",
    "        \n",
    "    def index_wrapper(self, index):\n",
    "        inds = [index*8, (index+1)*8]\n",
    "        times = [self.fd.DataSet.time[inds[0]], self.fd.DataSet.time[inds[1]]]\n",
    "        return inds, times\n",
    "    \n",
    "    def init(self):\n",
    "        index = 0\n",
    "        station = 0\n",
    "        dtype = \"datetime64[h]\"\n",
    "        vmax=1e2\n",
    "        vmin=1e-3\n",
    "        # get new values for frame\n",
    "        inds, times = self.index_wrapper(index)\n",
    "        # set new values in the plot\n",
    "        ax0 = self.fig.axes[0]\n",
    "        ax1 = self.fig.axes[1]\n",
    "        ax0.clear()\n",
    "        ax1.clear()\n",
    "        fd.plot(ax0, station=station, time=np.arange(*inds), \n",
    "                pointspec=np.arange(len(self.fd.DataSet.pointspec)), \n",
    "                plot_station=True, cmap=\"jet\", vmin=vmin, vmax=vmax, \n",
    "                station_kwargs=dict(color=\"black\", label=self.fd.station_names[station]), \n",
    "                cbar_kwargs=dict(label=\"s*m^3/kg\", orientation=\"horizontal\"))\n",
    "        fd.add_map(ax0)\n",
    "        ax0.set_title(f\"Footprint {self.fd.DataSet.time[inds[0]].values.astype(dtype)} - {self.fd.DataSet.time[inds[1]].values.astype(dtype)}\")\n",
    "        \n",
    "        ax1.set_title(f\"Effect of run duration in {self.fd.station_names[0]} (enhancement)\")\n",
    "        ax1.set_ylabel(\"Enhancement\")\n",
    "        ax1.set_xlabel(\"Maximal height [m]\")\n",
    "        ax1.plot(self.enh_dict[\"times\"], self.enh_dict[\"values\"], color=\"black\")\n",
    "        ax1.set_xlim(ax1.get_xlim()[::-1])\n",
    "        ax1.fill_betweenx([min(self.enh_dict[\"values\"]), max(self.enh_dict[\"values\"])], times[0], times[1], color=\"r\", alpha=0.3)\n",
    "        ax1.grid()\n",
    "        return\n",
    "    \n",
    "    def animate(self, index):\n",
    "        station = 0\n",
    "        dtype = \"datetime64[h]\"\n",
    "        vmax=1e2\n",
    "        vmin=1e-3\n",
    "        # get new values for frame\n",
    "        inds, times = self.index_wrapper(index)\n",
    "        # set new values in the plot\n",
    "        ax0 = self.fig.axes[0]\n",
    "        ax1 = self.fig.axes[1]\n",
    "        ax0.clear()\n",
    "        ax1.clear()\n",
    "        fd.plot(ax0, station=station, time=np.arange(*inds), \n",
    "                pointspec=np.arange(len(self.fd.DataSet.pointspec)), \n",
    "                plot_station=True, cmap=\"jet\", vmin=vmin, vmax=vmax, \n",
    "                station_kwargs=dict(color=\"black\", label=self.fd.station_names[station]), \n",
    "                add_colorbar=False)\n",
    "        fd.add_map(ax0)\n",
    "        ax0.set_title(f\"Footprint {self.fd.DataSet.time[inds[0]].values.astype(dtype)} - {self.fd.DataSet.time[inds[1]].values.astype(dtype)}\")\n",
    "        \n",
    "        ax1.set_title(f\"Effect of run duration in {self.fd.station_names[0]} (enhancement)\")\n",
    "        ax1.set_ylabel(\"Enhancement\")\n",
    "        ax1.set_xlabel(\"Time\")\n",
    "        ax1.plot(self.enh_dict[\"times\"], self.enh_dict[\"values\"], color=\"black\")\n",
    "        ax1.set_xlim(ax1.get_xlim()[::-1])\n",
    "        ax1.fill_betweenx([min(self.enh_dict[\"values\"]), max(self.enh_dict[\"values\"])], times[0], times[1], color=\"r\", alpha=0.3)\n",
    "        ax1.grid()\n",
    "        return\n",
    "    \n",
    "    def run(self):\n",
    "        self.ani = animation.FuncAnimation(self.fig, self.animate, 13,  init_func=self.init)\n",
    "        # ffmpeg is better but not available by default on the dkrz\n",
    "    def save(self):\n",
    "        writergif = animation.PillowWriter(fps=2) #can also set dpi\n",
    "        self.ani.save(\"/mnt/lustre01/pf/b/b381737/python_scripts/animations/test.gif\", writer=writergif, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = Animation(fd_unit_w)\n",
    "ani.run()\n",
    "ani.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign Country to data and choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = data.spec001_mr[dict(pointspec=[0,1,2])].sum(dim=[\"time\", \"pointspec\"])[0]\n",
    "gdf = xr_to_gdf(mass, \"spec001_mr\")\n",
    "gdf = add_country_names(gdf)\n",
    "#gdf.to_pickle(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20121123-20121207/gdf.pkl\")\n",
    "ci = country_inersections(gdf, \"Australia\")\n",
    "#intersections = country_inersections(mass, \"Australia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_pickle(\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20121123-20121207/gdf_woll_12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"Station\",\"Year\",\"Total [s]\", \"Australia [%]\", \"Other countries [%]\", \"Ocean [%]\"]\n",
    "df = pd.DataFrame(columns=columns)\n",
    "direc=\"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20121123-20121207/\"\n",
    "l = []\n",
    "for y in [\"09\", \"12\"]:\n",
    "    for stat in [\"woll\", \"dar\"]:\n",
    "    \n",
    "        l.append(\"Wollongong\" if stat == \"woll\" else \"Darwin\")\n",
    "        l.append(\"20\"+y)\n",
    "        path = f\"gdf_{stat}_{y}.pkl\"\n",
    "        print(path)\n",
    "        gdf = pd.read_pickle(direc+path)\n",
    "        ret = country_intersections(gdf, \"Australia\")\n",
    "        tot = gdf.spec001_mr.sum()\n",
    "        l.append(round(tot, 0))\n",
    "        for key in ret.keys():\n",
    "            if key == \"rest\":\n",
    "                continue\n",
    "            l.append(round(ret[key].spec001_mr.sum()/tot*100, 2))\n",
    "        df = df.append(dict(zip(columns,l)), ignore_index=True)\n",
    "        l = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for vmin\n",
    "mass = data.spec001_mr.where(data.spec001_mr!=0)\n",
    "#height index, vmin, vmax for cbar\n",
    "h_ind = 0\n",
    "vmin = np.min(mass.isel(pointspec=[0])).values\n",
    "vmax = np.max(mass.isel(pointspec=[0])).values\n",
    "print(vmin)\n",
    "print(vmax)\n",
    "\n",
    "#box to be shown TODO: prevent error if not standard projection\n",
    "extent=[0,180,-85,-0]\n",
    "\n",
    "cmap = \"jet\"\n",
    "norm = colors.LogNorm()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "#total number of frames\n",
    "frames=len(data.time.values)\n",
    "#milliseconds between frames\n",
    "interval=100\n",
    "\n",
    "def index_mod(index):\n",
    "    return index\n",
    "\n",
    "def add_to_ax(ax):\n",
    "    ax.scatter(114.1742, 22.3025,s=200, label=\"hko\", color=\"yellow\", edgecolor=\"black\", marker=\"*\")\n",
    "    #ax.scatter(16.1469, 49.0845, s=100, label=\"Power plant\", color=\"red\", marker=\"^\")\n",
    "    return ax\n",
    "\n",
    "def animate(index):\n",
    "    ind = index_mod(index)\n",
    "    ax.clear()\n",
    "    mass = data.spec001_mr.isel(time=[ind], height=[h_ind], pointspec=[0])\n",
    "    mass = mass.where(mass!=0)\n",
    "    if len(fig.axes)==1:\n",
    "        mass.plot(ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, \n",
    "                  norm=norm, \n",
    "                  transform=ccrs.PlateCarree(), \n",
    "                  cbar_kwargs=dict(label=\"Footprint [s]\"))\n",
    "    else:\n",
    "        mass.plot(ax=ax, cmap=cmap, vmin=vmin, vmax=vmax, \n",
    "                  norm=norm, \n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  add_colorbar=False)\n",
    "    ax.set_title(data.time.values[ind].astype('datetime64[h]'))\n",
    "    add_map(ax, extent=extent)\n",
    "    add_to_ax(ax)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames, interval=interval, blit=False)\n",
    "ani.save(\"/mnt/lustre01/pf/b/b381737/python_scripts/master/open_data/animations/australia/wu.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for vmin\n",
    "file_path = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/OD20180905/grid_conc_20180905000000.nc\"\n",
    "data1 = xr.open_dataset(file_path)\n",
    "mass1 = data1.spec001_mr\n",
    "file_path = \"/work/bb1170/RUN/b381737/software/flexpart_v10.4_3d7eebf/output/EI20180905/grid_conc_20180905000000.nc\"\n",
    "data2 = xr.open_dataset(file_path)\n",
    "mass2 = data2.spec001_mr\n",
    "mass2 = select_extent(mass2, 5, 25, 40, 55)\n",
    "\n",
    "mass1 = mass1.where(mass1!=0)\n",
    "mass2 = mass2.where(mass2!=0)\n",
    "\n",
    "\n",
    "\n",
    "#height index, vmin, vmax for cbar\n",
    "h_ind = 0\n",
    "vmin = min([np.min(mass1.isel(pointspec=[0])).values, np.min(mass2.isel(pointspec=[0])).values])\n",
    "vmax = max([np.max(mass1.isel(pointspec=[0])).values, np.max(mass2.isel(pointspec=[0])).values])\n",
    "print(vmin)\n",
    "print(vmax)\n",
    "\n",
    "#box to be shown TODO: prevent error if not standard projection\n",
    "extent=[15, 19, 46, 50]\n",
    "\n",
    "cmaps = [\"Blues\", \"Reds\"]\n",
    "labels = [\"Footprint [s] (IFS)\", \"Footprint [s] (Interim)\"]#[\"Footprint [s] (Interim)\", \"Footprint [s] (IFS)\"]\n",
    "norm = colors.LogNorm()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "\n",
    "#total number of frames\n",
    "frames=len(data1.time.values)\n",
    "#milliseconds between frames\n",
    "interval=100\n",
    "\n",
    "def index_mod(index):\n",
    "    return index\n",
    "\n",
    "def add_to_ax(ax):\n",
    "    #ax.scatter(114.1742, 22.3025,s=200, label=\"hko\", color=\"yellow\", edgecolor=\"black\", marker=\"*\")\n",
    "    #ax.scatter(16.1469, 49.0845, s=100, label=\"Power plant\", color=\"red\", marker=\"^\")\n",
    "    return ax\n",
    "\n",
    "def animate(index):\n",
    "    ind = index_mod(index)\n",
    "    ax.clear()\n",
    "    for i, mass in enumerate([mass1,mass2]):\n",
    "        mass = mass.isel(dict(time=ind, height=0))\n",
    "        mass = mass.where(mass!=0)\n",
    "        if len(fig.axes)==(i+1):\n",
    "            mass.plot(ax=ax, cmap=cmaps[i], vmin=vmin, vmax=vmax, \n",
    "                      norm=norm, \n",
    "                      transform=ccrs.PlateCarree(), \n",
    "                      cbar_kwargs=dict(label=labels[i]))\n",
    "        else:\n",
    "            mass.plot(ax=ax, cmap=cmaps[i], vmin=vmin, vmax=vmax, \n",
    "                      norm=norm, \n",
    "                      transform=ccrs.PlateCarree(),\n",
    "                      add_colorbar=False)\n",
    "    ax.set_title(data1.time.values[ind].astype('datetime64[h]'))\n",
    "    add_map(ax, extent=extent)\n",
    "    add_to_ax(ax)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames, interval=interval, blit=False)\n",
    "ani.save(\"/mnt/lustre01/pf/b/b381737/python_scripts/master/open_data/animations/tutorial/vienna_comparision2.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot env",
   "language": "python",
   "name": "plot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
